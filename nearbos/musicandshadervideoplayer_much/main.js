import { setupWebGL } from './webgl.js';
import wasmBytesBase64 from './much.wasm.base64.js';
import shadersource from './shadersource.js';
import { setProgressbarValue } from './progress-bar.js';
import { decodeBufferFromPNG } from './png.js';

const wasmBytes = await decodeBufferFromPNG(wasmBytesBase64);

const sampleRate = 44100;

const durationFrames = sampleRate - (sampleRate % 128);
const durationMillis = durationFrames * 1000.0 / sampleRate;
const songLengthMillis = 188000;
const numBuffers = Math.floor(songLengthMillis / durationMillis);

let songStartTime;

let audioCtx;
let audioBufSrcNode;

const playbutton = document.getElementById('playbutton');

const worker = new Worker(new URL('renderworker.js', import.meta.url), { type: 'module' });

const buffers = [];

const scrollTextElement = document.querySelector('#scrolltext');
let scrollTextElementPos = document.documentElement.clientWidth;
scrollTextElement.style.left = `${scrollTextElementPos}px`;

async function createBuffers(sendWasm = false) {
    const { leftbuffer, rightbuffer, activeVoicesStatusSnaphots } = await new Promise(async resolve => {
        worker.postMessage({
            wasm: sendWasm ? wasmBytes : undefined,
            samplerate: sampleRate,
            songduration: durationMillis
        });
        worker.onmessage = msg => {
            if (msg.data.leftbuffer) {
                resolve(msg.data);
            } else {
                //document.querySelector('#loaderprogress').innerHTML = (msg.data.progress * 100).toFixed(2) + '%';
            }
        }
    });
    buffers.push({ leftbuffer, rightbuffer, activeVoicesStatusSnaphots });
}

const result = await fetch('https://rpc.mainnet.near.org', {
    method: 'POST',
    headers: {
        'content-type': 'application/json'
    },
    body: JSON.stringify({
        "jsonrpc": "2.0",
        "id": "dontcare",
        "method": "query",
        "params": {
            "request_type": "call_function",
            "finality": "final",
            "account_id": "jsinrustnft.near",
            "method_name": "nft_token",
            "args_base64": btoa(JSON.stringify({ token_id: 'much' }))
        }
    })
}).then(r => r.json());
const nftdata = JSON.parse(result.result.result.map(c => String.fromCharCode(c)).join(''));

scrollTextElement.innerHTML = `${nftdata?.owner_id} presents ${nftdata?.metadata.title} - ${nftdata?.metadata.description}.    `+
    `This is music and shaders stored entirely in a NEAR BOS widget less than 50Kb, made possible using "WebAssembly Music" which is `+
    `a technology and app that embeds code to generate digital instruments and orchestrate them from a tiny wasm file. `+
    `Google "WebAssembly Music" to learn more. With NEAR Blockchain Operating System it's also possible to publish the music as `+
    `"widgets" with the appearance of your own choice ( like shader graphics used here for example ), and that will also persist for the future. `+
    `You'll also find this music on regular streaming platforms, but the presence there relies on the author paying the annual fees, while here `+
    `on NEAR BOS there are no such recurring commitments. Another thing is that the music on streaming services are encoded in a compressed format. `+
    `Maybe you are not able to tell the difference, but I can assure you that what you hear here is exactly as it should be without `+
    `audio compression. The instruments you hear are not recorded, they are generated by math in the code, applying principles from `+
    `physical modeling of sound that gives quite a realistic feel to the instruments.    Finally, this is an NFT, currently owned by `+
    `${nftdata?.owner_id}.   Check out NFT marketplaces like Mintbase if it's for sale, and it will be your account name in the beginning `+
    `that shows as the presenter of this.   And also the NFT points to a picture to catch the vibe of this music. Either you think it's "too much", `+
    `or it actually gives you a good feeling, which I hope it does. Enjoy!`;


let chunkStartTime;

const startAudioBufSrcNode = async () => {
    for (let bufferNdx = 0; audioCtx && bufferNdx < numBuffers; bufferNdx++) {
        while (!buffers[bufferNdx]) {
            await new Promise(r => setTimeout(() => r(), 1));
        }
        const audioBuf = audioCtx.createBuffer(2, durationFrames, sampleRate);
        audioBuf.getChannelData(0).set(new Float32Array(buffers[bufferNdx].leftbuffer));
        audioBuf.getChannelData(1).set(new Float32Array(buffers[bufferNdx].rightbuffer));
        audioBufSrcNode = audioCtx.createBufferSource();
        audioBufSrcNode.buffer = audioBuf;

        audioBufSrcNode.connect(audioCtx.destination);
        audioBufSrcNode.loop = false;
        audioBufSrcNode.start(chunkStartTime);
        chunkStartTime += durationMillis / 1000.0;
    }
};

if (audioCtx && audioBufSrcNode) {
    audioBufSrcNode.stop();
    audioBufSrcNode.disconnect();
    audioBufSrcNode = null;
    startAudioBufSrcNode();
}

playbutton.onclick = async () => {
    try {
        playbutton.style.visibility = 'hidden';

        if (audioCtx) {
            audioCtx.close();
            audioCtx = null;
            return;
        }
        audioCtx = new AudioContext();

        setProgressbarValue(0);

        let renderStartTime = new Date().getTime();

        const totalDurationMillis = durationMillis * numBuffers;
        let timeNotYetRendered = totalDurationMillis;
        let estimatedRenderTimeLeft = timeNotYetRendered * 2;
        let audiorendererror;
        (async () => {
            try {
                await createBuffers(true);
                timeNotYetRendered -= durationMillis;
                for (let n = 1; n < numBuffers; n++) {
                    await createBuffers();

                    estimatedRenderTimeLeft = ((numBuffers - n) * (new Date().getTime() - renderStartTime) / n);
                    timeNotYetRendered = durationMillis * (numBuffers - n);
                }
                estimatedRenderTimeLeft = 0;
                timeNotYetRendered = 0;
            } catch (e) {
                audiorendererror = e;
            }
        })();

        while (!audiorendererror && estimatedRenderTimeLeft > timeNotYetRendered) {
            setProgressbarValue((totalDurationMillis - timeNotYetRendered) / totalDurationMillis, 'rendering audio');
            await new Promise(r => setTimeout(() => r(), 1));
        }

        if (audiorendererror) {
            throw audiorendererror;
        }
        setProgressbarValue(null);

        try {
            // await document.documentElement.requestFullscreen();
        } catch (e) {
            console.error('full screen not possible');
        }
        const getCurrentTime = () => (songStartTime && audioCtx?.currentTime - songStartTime) ?? 0;
        setupWebGL(shadersource, document.getElementById('videocanvas'), () => audioCtx?.currentTime - songStartTime ?? 0, () => {
            const currentTimeMillis = getCurrentTime() * 1000;
            const bufferpos = Math.floor(currentTimeMillis / durationMillis);
            const targetNoteStates = new Array(128).fill(-1);
            
            if (bufferpos >= buffers.length) {
                chunkStartTime = audioCtx.currentTime + bufferingtime;
                songStartTime = chunkStartTime;
                startAudioBufSrcNode();
            } else if (bufferpos >= 0) {
                const voiceStatusArrLength = 32 * 3;
                const snapshotBufferPos = voiceStatusArrLength * Math.floor((durationFrames * (currentTimeMillis % durationMillis) / durationMillis) / 128);

                const voiceStatusArr = new Uint8Array(buffers[bufferpos].activeVoicesStatusSnaphots, snapshotBufferPos, voiceStatusArrLength);

                for (let n = 0; n < voiceStatusArr.length; n += 3) {
                    targetNoteStates[voiceStatusArr[n + 1]] = ((voiceStatusArr[n + 2] / 127) * 2 - 1);
                }
            }
            return targetNoteStates;
        });

        const bufferingtime = 0.2;
        chunkStartTime = audioCtx.currentTime + bufferingtime;
        songStartTime = chunkStartTime;
        startAudioBufSrcNode();

        const scrollText = () => requestAnimationFrame(() => {
            scrollTextElement.style.left = `${scrollTextElementPos--}px`;
            if (scrollTextElementPos === -scrollTextElement.clientWidth) {
                scrollTextElementPos = document.documentElement.clientWidth;
            }
            scrollText();
        });
        scrollText();
    } catch (e) {
        setProgressbarValue(null);
        document.body.innerHTML = e;
    }
};

